{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "2bWvPLSZmBTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c257798-5b0e-4faf-f647-dd2e00b5d19b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TzwVCEDGjzSZ"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import os\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as k\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTQz3TTWjzSg"
      },
      "source": [
        "### 1. Load Test and Train Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DOkujMjzSk",
        "outputId": "a527abda-ed8e-4865-83ea-fc86f7dd713a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381 164\n"
          ]
        }
      ],
      "source": [
        "files_train = 0\n",
        "files_validation = 0\n",
        "\n",
        "cwd = os.getcwd()\n",
        "folder = '/content/drive/MyDrive/parking_spots_detector/train_data/train'\n",
        "for sub_folder in os.listdir(folder):\n",
        "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
        "    files_train += len(files)\n",
        "\n",
        "\n",
        "folder = '/content/drive/MyDrive/parking_spots_detector/train_data/test'\n",
        "for sub_folder in os.listdir(folder):\n",
        "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
        "    files_validation += len(files)\n",
        "\n",
        "print(files_train,files_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TJhFxagjzSo"
      },
      "source": [
        "### 2. Set key parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1JxQsDWWjzSp"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 128,128\n",
        "train_data_dir = \"/content/drive/MyDrive/parking_spots_detector/train_data/train\"\n",
        "validation_data_dir = \"/content/drive/MyDrive/parking_spots_detector/train_data/test\"\n",
        "nb_train_samples = files_train\n",
        "nb_validation_samples = files_validation\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdHEQXirjzSq"
      },
      "source": [
        "### 3. Build model on top of a trained VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lTAmW-8DjzSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abaaa49-a712-4eb4-ec75-276969994675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
        "\n",
        "for layer in model.layers[:10]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uwQg9L_hjzSs"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as kera\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
        "\n",
        "X=Flatten()(model.output)\n",
        "X=Dense(units=2,activation='softmax')(X)\n",
        "# X = BatchNormalization()(X)  # Add BatchNormalization layer\n",
        "\n",
        "#  creating our model\n",
        "model=Model(model.input,X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Q8JBtRBmof",
        "outputId": "d391fb63-717d-48e6-af61-88f96fd24939"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 16386     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14731074 (56.19 MB)\n",
            "Trainable params: 12995586 (49.57 MB)\n",
            "Non-trainable params: 1735488 (6.62 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwBMznNLjzSt",
        "outputId": "879228ca-6df0-4ead-ae94-7127cea4b7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 381 images belonging to 2 classes.\n",
            "Found 164 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Initiate the train and test generators with data Augumentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.1,\n",
        "width_shift_range = 0.1,\n",
        "height_shift_range=0.1,\n",
        "rotation_range=5)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.1,\n",
        "width_shift_range = 0.1,\n",
        "height_shift_range=0.1,\n",
        "rotation_range=5)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_data_dir,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size,\n",
        "class_mode = \"categorical\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "validation_data_dir,\n",
        "target_size = (img_height, img_width),\n",
        "class_mode = \"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w-QJKq7jzSv",
        "outputId": "8c484b68-deda-4b75-aaf9-c7c7868d1aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "# Save the model according to the conditions\n",
        "checkpoint = ModelCheckpoint(\"car1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "z66TML5Lk-Lf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_u9V24TjzSw",
        "outputId": "eebf9de3-62c2-40ec-c926-510644a13383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-79c4311a7792>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history_object = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7743 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 319s 27s/step - loss: 0.4455 - accuracy: 0.7743 - val_loss: 0.2054 - val_accuracy: 0.9085\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9344 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 182s 15s/step - loss: 0.1770 - accuracy: 0.9344 - val_loss: 0.3257 - val_accuracy: 0.8841\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9370 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 182s 15s/step - loss: 0.1641 - accuracy: 0.9370 - val_loss: 0.2955 - val_accuracy: 0.9085\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9528 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 188s 16s/step - loss: 0.1319 - accuracy: 0.9528 - val_loss: 0.2775 - val_accuracy: 0.9207\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9790 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 188s 16s/step - loss: 0.0782 - accuracy: 0.9790 - val_loss: 0.2432 - val_accuracy: 0.9573\n"
          ]
        }
      ],
      "source": [
        "### Start training!\n",
        "\n",
        "history_object = model.fit_generator(\n",
        "train_generator,\n",
        "epochs = epochs,\n",
        "validation_data = validation_generator,\n",
        "callbacks = [checkpoint, early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8nZcYHX6jzSz"
      },
      "outputs": [],
      "source": [
        "ref = dict(zip(list(train_generator.class_indices.values()),list(train_generator.class_indices.keys())))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg19 import VGG19,preprocess_input,decode_predictions\n",
        "\n",
        "from tensorflow.keras.utils import img_to_array,load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CRREinzCnalG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(path):\n",
        "  img=load_img(path,target_size=(128,128))\n",
        "  i=img_to_array(img)\n",
        "  im=preprocess_input(i)\n",
        "  # print(im.shape)\n",
        "  img=np.expand_dims(im,axis=0)\n",
        "  # print(img.shape)\n",
        "  pred=np.argmax(model.predict(img))\n",
        "  # print(pred)\n",
        "  print(f\"The image belongs to {ref[pred]}\")"
      ],
      "metadata": {
        "id": "7DzGkEADlYQt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/parking_spots_detector/test_images/scene1380.jpg\"\n",
        "\n",
        "prediction(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnJteMHtlZz0",
        "outputId": "8262b35a-4e68-4b52-dd1b-505151e8b17c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 362ms/step\n",
            "The image belongs to occupied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as a pickle file\n",
        "import pickle\n",
        "\n",
        "model_dict = {'model': model.to_json(), 'weights': model.get_weights()}\n",
        "\n",
        "with open('/content/drive/MyDrive/parking_spots_detector/spot_dict.pickle', 'wb') as f:\n",
        "    pickle.dump(model_dict,f)"
      ],
      "metadata": {
        "id": "_vZNgSMBD0kX"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}